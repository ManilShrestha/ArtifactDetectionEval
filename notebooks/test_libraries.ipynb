{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "from lib.CustomDataset import TimeSeriesHDF5Dataset\n",
    "from lib.Utilities import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:41:09 :\t  Reading /storage/ms5267@drexel.edu/precicecap_downloads/90_Patient_2023-03-21_12:19.h5 \n",
      "\n",
      "18:41:09 :\t  Sampling frequency for this file is: 125 \n",
      "\n",
      "18:41:09 :\t  There are a total of : 4586 segments of 10 seconds with overlap of 50.0% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = '/storage/ms5267@drexel.edu/precicecap_downloads/90_Patient_2023-03-21_12:19.h5'\n",
    "t  = TimeSeriesHDF5Dataset(filepath, 'Waveforms/ABP_na','Waveforms/ABP_na_Timestamps',10,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:41:10 :\t  Reading /storage/ms5267@drexel.edu/precicecap_downloads/90_Patient_2023-03-21_12:19.h5 \n",
      "\n",
      "18:41:10 :\t  Sampling frequency for this file is: 500 \n",
      "\n",
      "18:41:10 :\t  Frequency will be resampled to 125Hz. \n",
      "\n",
      "18:41:10 :\t  There are a total of : 4586 segments of 10 seconds with overlap of 50.0% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "filepath = '/storage/ms5267@drexel.edu/precicecap_downloads/90_Patient_2023-03-21_12:19.h5'\n",
    "t  = TimeSeriesHDF5Dataset(filepath, 'Waveforms/ECG_II','Waveforms/ECG_II_Timestamps',10,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  39767   40392]\n",
      " [ 332635  333385]\n",
      " [ 256794  256919]\n",
      " [ 256919  257544]\n",
      " [ 255170  255795]\n",
      " [ 522176  524175]\n",
      " [ 335384  347754]\n",
      " [     35      35]\n",
      " [ 194197  194697]\n",
      " [  34646   34771]\n",
      " [ 227932  228432]\n",
      " [  99111   99486]\n",
      " [ 307147  307522]\n",
      " [ 308396  308771]\n",
      " [ 805175  805799]\n",
      " [1032074 1032448]\n",
      " [1125157 1125282]\n",
      " [1287960 1369173]\n",
      " [1857456 1857706]\n",
      " [2270522 2272895]\n",
      " [2821519 2822518]\n",
      " [ 976099 1003836]\n",
      " [1047817 1048066]\n",
      " [1084675 1085175]\n",
      " [1939919 1955787]\n",
      " [2294886 2295136]\n",
      " [1852708 1852958]\n",
      " [1021078 1029450]\n",
      " [1102667 1111413]\n",
      " [1269718 1283462]\n",
      " [2618236 2618611]\n",
      " [2816521 2817770]\n",
      " [ 308521  308771]\n",
      " [ 100860  101110]\n",
      " [ 227932  228557]\n",
      " [ 335384  347754]\n",
      " [     35      35]\n",
      " [  34646   34771]\n",
      " [     35      35]\n",
      " [ 194322  194697]\n",
      " [  37019   37144]\n",
      " [ 332510  333760]\n",
      " [2867623 2867623]\n",
      " [ 255295  257544]\n",
      " [2867623 2867623]\n",
      " [  39517   40517]\n",
      " [ 307147  307522]\n",
      " [  97986   99611]\n",
      " [ 521426  524300]\n",
      " [1007210 1007460]\n",
      " [1489120 1489745]\n",
      " [2089352 2091601]\n",
      " [2613238 2613863]\n",
      " [2802527 2803527]\n",
      " [1069682 1071806]\n",
      " [1992520 2061615]\n",
      " [2286265 2287889]\n",
      " [ 572403  573153]\n",
      " [1033698 1038321]\n",
      " [2061615 2067987]\n",
      " [2307880 2308130]\n",
      " [2630855 2631105]\n",
      " [1038696 1041944]\n",
      " [1080052 1081926]\n",
      " [1249727 1250851]\n",
      " [1369173 1373047]\n",
      " [1834591 1842088]\n",
      " [1038321 1038696]\n",
      " [2583876 2584376]\n",
      " [2774790 2802527]\n",
      " [ 797428  797553]\n",
      " [1041944 1042819]\n",
      " [1049941 1050315]\n",
      " [1153394 1154519]\n",
      " [1825220 1825845]\n",
      " [1957286 1959535]\n",
      " [1092047 1092297]\n",
      " [1283462 1287960]\n",
      " [1493118 1493493]\n",
      " [2187559 2200178]\n",
      " [2615612 2616362]\n",
      " [2810899 2811523]\n",
      " [1285086 1287460]\n",
      " [2237286 2237411]\n",
      " [2773915 2802652]\n",
      " [1493243 1493368]\n",
      " [1079927 1080802]\n",
      " [1834591 1835216]\n",
      " [1940044 1959535]\n",
      " [2613113 2613863]\n",
      " [2802652 2803402]\n",
      " [1020954 1026201]\n",
      " [1269968 1284961]\n",
      " [2583876 2584501]\n",
      " [1287460 1369298]\n",
      " [2189433 2200178]\n",
      " [ 805300  805674]\n",
      " [1069682 1071806]\n",
      " [2270397 2272646]\n",
      " [2615737 2616112]\n",
      " [2810899 2817646]\n",
      " [1026826 1042944]\n",
      " [1738009 1738509]\n",
      " [2821519 2822393]\n",
      " [ 572528  573028]\n",
      " [1153519 1154269]\n",
      " [1369298 1372922]\n",
      " [1986773 2069361]\n",
      " [1047817 1048066]\n",
      " [1249727 1250851]\n",
      " [1836715 1841963]\n",
      " [2618361 2618486]\n",
      " [1857456 1857581]\n",
      " [2867623 2867623]\n",
      " [1084675 1085050]\n",
      " [ 976099 1003711]\n",
      " [1489245 1489745]\n",
      " [1049816 1050190]\n",
      " [1825095 1825720]\n",
      " [1852708 1852958]\n",
      " [2089227 2091476]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "config_path = '../config.yaml'\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "annotation_dir = config['annotation_dir']\n",
    "\n",
    "def load_annotation_file(ann_file_path):\n",
    "    import pandas as pd\n",
    "\n",
    "    def convert_bytes(b):\n",
    "        # Convert byte string literals found in the CSV to string removing b' and '\n",
    "        if isinstance(b, bytes):\n",
    "            return b.decode('utf-8').strip(\"b'\").strip(\"'\")\n",
    "        return b.strip(\"b'\").strip(\"'\")\n",
    "\n",
    "\n",
    "    # Load the CSV file, applying conversion to all columns\n",
    "    df = pd.read_csv(ann_file_path, converters={i: convert_bytes for i in range(8)}, header=None)\n",
    "\n",
    "    # Rename columns if needed (assuming you know what each column represents)\n",
    "    df.columns = ['ID1', 'ID2', 'Session', 'Data_Type', 'Start_Time', 'End_Time', 'Signal_Type', 'Lead_Type']\n",
    "\n",
    "    return df\n",
    "\n",
    "def is_artifact_overlap(file_path, mode, candidate_interval):\n",
    "    \"\"\"Finds if the given indices contain artifact or not\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path of the datafile, this is to get the name of file\n",
    "        mode (str): Either ABP or ECG\n",
    "        start_idx (int): Start index\n",
    "        end_idx (int): End index\n",
    "    \"\"\"\n",
    "    import os\n",
    "    file_name = os.path.basename(file_path)\n",
    "    annotation_file_name = annotation_dir + file_name + '-annotations.csv'\n",
    "    annotation_df = load_annotation_file(annotation_file_name)\n",
    "\n",
    "    if mode == 'ABP':\n",
    "        filter = ['ABP', 'ART', 'ART1', 'ART2']\n",
    "    else:\n",
    "        filter = 'ECG'\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    filtered_df = annotation_df[annotation_df.iloc[:, -2].isin(filter)]\n",
    "    # Extract the first two columns and convert to NumPy array\n",
    "    artifact_arr = filtered_df.iloc[:, :2].astype(int).to_numpy()\n",
    "\n",
    "    # Print the resulting NumPy array\n",
    "    print(artifact_arr)\t\n",
    "    return has_artifact(candidate_interval, artifact_arr)\n",
    "\n",
    "\n",
    "def has_artifact(candidate_interval, artifacts):\n",
    "    for artifact in artifacts:\n",
    "        # Calculate the maximum start time and minimum end time between candidate_interval and artifact\n",
    "        start_max = max(candidate_interval[0], artifact[0])\n",
    "        end_min = min(candidate_interval[1], artifact[1])\n",
    "        \n",
    "        # Check for overlap\n",
    "        if start_max < end_min:\n",
    "            # If there is an overlap, return True\n",
    "            return True\n",
    "    \n",
    "    # If no overlap is found with any artifact, return False\n",
    "    return False\n",
    "\n",
    "\n",
    "datafile = '/storage/ms5267@drexel.edu/precicecap_downloads/90_Patient_2023-03-21_12:19.h5'\n",
    "is_artifact_overlap(datafile, 'ABP', [523176,622176])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879d41a785fc4568824e6c862ba5014c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:32:43 :\t  Processing 59_Patient_2022-01-31_23:19.h5 \n",
      "\n",
      "17:32:44 :\t  Processing 74_Patient_2023-08-05_06:00.h5 \n",
      "\n",
      "17:33:41 :\t  Processing 110_Patient_2023_Sep_28__23_52_07_705708.h5 \n",
      "\n",
      "17:36:13 :\t  Processing 90_Patient_2023-03-21_19:57.h5 \n",
      "\n",
      "17:37:54 :\t  Processing 4_Patient_2022-02-05_08:59.h5 \n",
      "\n",
      "17:37:55 :\t  Processing 73_Patient_2017_Dec_18__11_19_55_297272.h5 \n",
      "\n",
      "17:37:58 :\t  Processing 34_Patient_2023-04-04_22:31.h5 \n",
      "\n",
      "17:38:00 :\t  Processing 53_Patient_2023-06-25_21:39.h5 \n",
      "\n",
      "17:38:01 :\t  Processing 101_Patient_2023_Nov_9__22_24_41_155873.h5 \n",
      "\n",
      "17:38:43 :\t  Processing 90_Patient_2023-03-21_12:19.h5 \n",
      "\n",
      "17:38:46 :\t  Processing 50_Patient_2023-06-12_21:10.h5 \n",
      "\n",
      "17:39:39 :\t  Processing 35_Patient_2023-04-03_19:51.h5 \n",
      "\n",
      "17:39:40 :\t  Processing 55_Patient_2023-06-13_00:47.h5 \n",
      "\n",
      "17:41:07 :\t  Processing 139_Patient_2024_Mar_4__7_32_51_662674.h5 \n",
      "\n",
      "17:41:13 :\t  Processing 34_Patient_2023-04-05_12:23.h5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from lib.CustomDataset import TimeSeriesHDF5Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "############### SCRIPT VARIABLES #######################\n",
    "config_path = '../config.yaml'\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "segment_length_sec = config['segment_length_sec']\n",
    "sampling_rate = config['sampling_rate']\n",
    "overlap = config['overlap']\n",
    "\n",
    "latent_dim = 20\n",
    "lr = 1e-4\n",
    "epochs = 5\n",
    "batch_size=64\n",
    "percentile_threshold = 99.9\n",
    "n=0\n",
    "\n",
    "device = 'cpu'\n",
    "best_model_path = 'models/deep_clean_abp_best.pt'\n",
    "directory_path = '/storage/ms5267@drexel.edu/precicecap_downloads/'\n",
    "mode = 'ABP'\n",
    "#########################################################\n",
    "\n",
    "def compute_mean_std(train_files):\n",
    "    # Initialize sum and sum of squares\n",
    "    sum_data = torch.zeros((1, int(segment_length_sec * sampling_rate)), device='cuda')\n",
    "    sum_sq_data = torch.zeros((1,int(segment_length_sec * sampling_rate)), device='cuda')\n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for filename in tqdm(train_files):\n",
    "            log_info(f\"Processing {filename}\")\n",
    "            datafile = os.path.join(directory_path, filename)\n",
    "\n",
    "            # Load the dataset\n",
    "            dataset = TimeSeriesHDF5Dataset(datafile, mode, segment_length_sec, overlap)\n",
    "            dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "            # Loop through batches in the DataLoader\n",
    "            for _, data, _ in dataloader:\n",
    "                filter = filter_batch(data)\n",
    "                data = data.unsqueeze(1).float().to(device)[filter]\n",
    "                \n",
    "                data = data.to('cuda')  # Ensure data is on GPU\n",
    "                sum_data += torch.sum(data, dim=0)\n",
    "                sum_sq_data += torch.sum(data ** 2, dim=0)\n",
    "                # Update sample count\n",
    "                n += len(data)\n",
    "    # Compute mean and standard deviation\n",
    "    mean = sum_data / n\n",
    "    std_dev = torch.sqrt(sum_sq_data / n - mean ** 2)\n",
    "\n",
    "    return mean, std_dev\n",
    "\n",
    "train_files = ['59_Patient_2022-01-31_23:19.h5'\n",
    ", '74_Patient_2023-08-05_06:00.h5'\n",
    ", '110_Patient_2023_Sep_28__23_52_07_705708.h5'\n",
    ", '90_Patient_2023-03-21_19:57.h5', '4_Patient_2022-02-05_08:59.h5', '73_Patient_2017_Dec_18__11_19_55_297272.h5', '34_Patient_2023-04-04_22:31.h5', '53_Patient_2023-06-25_21:39.h5', '101_Patient_2023_Nov_9__22_24_41_155873.h5', '90_Patient_2023-03-21_12:19.h5', '50_Patient_2023-06-12_21:10.h5', '35_Patient_2023-04-03_19:51.h5', '55_Patient_2023-06-13_00:47.h5', '139_Patient_2024_Mar_4__7_32_51_662674.h5', '34_Patient_2023-04-05_12:23.h5']\n",
    "mean, std= compute_mean_std(train_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1250]), torch.Size([1, 1250]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.shape, std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mean, '../models/mean_abp_10sec')\n",
    "torch.save(std, '../models/std_abp_10sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[79.6564, 79.1526, 78.6991,  ..., 77.3311, 77.6051, 77.9201]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(101781.5703, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[28.4017, 28.0697, 27.7477,  ..., 24.9447, 24.8768, 24.7370]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "mean = torch.load('../models/mean_ecg_10sec')\n",
    "std = torch.load('../models/std_ecg_10sec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.6175e-02,  3.4293e-02,  2.1703e-02,  ..., -3.8359e-05,\n",
       "          -2.2871e-02,  1.6050e-02]], device='cuda:2'),\n",
       " tensor([[0.4039, 0.7181, 0.6091,  ..., 0.1972, 0.1942, 0.1896]],\n",
       "        device='cuda:2'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(222.5967, device='cuda:2')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2665"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/storage/ms5267@drexel.edu/precicecap_downloads/4_Patient_2022-02-05_08:59.h5'\n",
    "dataset  =TimeSeriesHDF5Dataset(filepath, 'ART', 3, 0.5)    \n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve-m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
