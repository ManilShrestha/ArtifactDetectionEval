{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from lib.CustomDataset import TimeSeriesHDF5Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from lib.VAE import VAE\t\n",
    "from lib.Utilities import *\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from lib.FE_ExtractFeatures import ExtractFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_length_sec = 30\n",
    "sampling_rate = config['sampling_rate']\n",
    "overlap = 0.95\n",
    "directory_path = config['hdf5_file_dir']\n",
    "mode = ['ABP','ART']\n",
    "\n",
    "\n",
    "hdf5_files = ['4_Patient_2022-02-05_08:59.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:53:08 :\t  Processing 4_Patient_2022-02-05_08:59.h5 \n",
      "\n",
      "14:53:08 :\t  No Waveforms/ABP_na in the hdf5 file: <HDF5 file \"4_Patient_2022-02-05_08:59.h5\" (mode r)>. \n",
      "\n",
      "No data to process, continuing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "features_all = []\n",
    "\n",
    "for filename in tqdm(hdf5_files):\n",
    "\tlog_info(f\"Processing {filename}\")\n",
    "\tdatafile = os.path.join(directory_path, filename)\n",
    "\t\n",
    "\t# Load the dataset\n",
    "\tfor m in mode:\n",
    "\t\tdataset  = TimeSeriesHDF5Dataset(datafile, m, segment_len=segment_length_sec, overlap=overlap, phase=\"train\", smoothen=False) \n",
    "\n",
    "\t\tif len(dataset)==0:\n",
    "\t\t\tprint(\"No data to process, continuing...\")\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tdataloader = DataLoader(dataset, batch_size=32, num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "\t\tartifact_count, non_artifact_count= 0,0\n",
    "\t\t\n",
    "\n",
    "\t\ttotal_count =0\n",
    "\t\tfor start_i, data, lbl, ts in tqdm(dataloader):\n",
    "\t\t\tfilter = filter_abp_batch_scae(data)\n",
    "\t\t\t\n",
    "\t\t\tstart_i = start_i[filter]\n",
    "\t\t\tdata = data[filter]\n",
    "\t\t\tlbl = lbl[filter]\n",
    "\t\t\tts = ts[filter]\n",
    "\n",
    "\t\t\tif len(start_i)>0:\n",
    "\t\t\t\tfor b_n in range(len(start_i)):\n",
    "\t\t\t\t\tstart_idx = start_i[b_n]\n",
    "\t\t\t\t\tlabel = lbl[b_n]\n",
    "\t\t\t\t\ttimestamp  = ts[b_n]\n",
    "\t\t\t\t\tsignal_data = data[b_n]\n",
    "\n",
    "\t\t\t\t\tif label==1:\n",
    "\t\t\t\t\t\tartifact_count+=1\n",
    "\t\t\t\t\t\tinput_data = signal_data.unsqueeze(dim=0).numpy()\n",
    "\t\t\t\t\t\tfeatures = ExtractFeatures(input_data).get_features().squeeze()\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tper_segment_features = [datafile, m, label.item()] + features.tolist()\n",
    "\t\t\t\t\t\tfeatures_all.append(per_segment_features)\n",
    "\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = ['4_Patient_2022-02-05_08:59.h5','4_Patient_2022-02-05_08:59.h5']\n",
    "test_file = ['4_Patient_2022-02-05_08:59.h5']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "features_csv_file = '/home/ms5267@drexel.edu/moberg-precicecap/ArtifactDetectionEval/data/FE_features_train.csv'\n",
    "mode = ['ABP','ART']\n",
    "\n",
    "df = pd.read_csv(features_csv_file, header=None)\n",
    "\n",
    "train_features = df[df[0].isin(train_files)][df[1].isin(mode)]\n",
    "\n",
    "test_features = df[df[0].isin(test_file)][df[1].isin(mode)]\n",
    "\n",
    "# Training data\n",
    "train_labels = train_features.iloc[:, 2].to_numpy()\n",
    "X_train = train_features.iloc[:, 3:].to_numpy()\n",
    "\n",
    "# Test data\n",
    "test_labels = test_features.iloc[:, 2].to_numpy()\n",
    "X_test = test_features.iloc[:, 3:].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72.31704712, 65.875     , 20.60549927, ...,  0.296     ,\n",
       "         1.176     , 46.22127151],\n",
       "       [72.0506134 , 65.1875    , 20.69827652, ...,  0.296     ,\n",
       "         1.176     , 43.9915657 ],\n",
       "       [72.15585327, 65.8125    , 20.51646042, ...,  0.296     ,\n",
       "         1.176     , 43.42429733],\n",
       "       ...,\n",
       "       [37.56868362, 36.5625    ,  4.36484241, ...,  0.296     ,\n",
       "         0.776     , 14.41522408],\n",
       "       [62.59261703, 58.        , 15.92419529, ...,  0.304     ,\n",
       "         0.984     , 32.14121246],\n",
       "       [56.2902832 , 52.1875    , 13.82932854, ...,  0.296     ,\n",
       "         1.152     , 44.97563934]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def train_and_eval_SVM(X_train, y_train, X_test, y_test):\n",
    "    log_info(\"Training with SVM\")\n",
    "    svm_classifier = SVC(kernel='rbf')\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "    log_info(\"Evaluating the SVM classifier\")\n",
    "    y_pred_train = svm_classifier.predict(X_train)\n",
    "    log_info(f\"Train Accuracy: {accuracy_score(y_train, y_pred_train)}\\n{classification_report(y_train, y_pred_train)}\\n{confusion_matrix(y_train, y_pred_train)}\")\n",
    "    \n",
    "    y_pred_test = svm_classifier.predict(X_test)\n",
    "    log_info(f\"Test Accuracy: {accuracy_score(y_test, y_pred_test)}\\n{classification_report(y_test, y_pred_test)}\\n{confusion_matrix(y_test, y_pred_test)}\")\n",
    "\n",
    "    log_info(f\"Saving the trained SVM model\")\n",
    "    save_model(svm_classifier, 'models/svm_classifier_afib.pkl')\n",
    "\n",
    "\n",
    "def train_and_eval_KNN(X_train, y_train, X_test, y_test, n_neighbors=5):\n",
    "    log_info(\"Training with KNN\")\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "    log_info(\"Evaluating the KNN classifier\")\n",
    "    y_pred_train = knn_classifier.predict(X_train)\n",
    "    log_info(f\"Train Accuracy: {accuracy_score(y_train, y_pred_train)}\")\n",
    "    log_info(f\"{classification_report(y_train, y_pred_train)}\")\n",
    "    log_info(f\"{confusion_matrix(y_train, y_pred_train)}\")\n",
    "\n",
    "    y_pred_test = knn_classifier.predict(X_test)\n",
    "    log_info(f\"Test Accuracy: {accuracy_score(y_test, y_pred_test)}\")\n",
    "    log_info(f\"{classification_report(y_test, y_pred_test)}\")\n",
    "    log_info(f\"{confusion_matrix(y_test, y_pred_test)}\")\n",
    "\n",
    "    log_info(\"Saving the trained KNN model\")\n",
    "    save_model(knn_classifier, 'models/knn_classifier_afib.pkl')\n",
    "\n",
    "\n",
    "def train_and_eval_DT(X_train, y_train, X_test, y_test, max_depth=None, criterion='gini'):\n",
    "    log_info(\"Training with Decision Tree\")\n",
    "    dt_classifier = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion)\n",
    "    dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "    log_info(\"Evaluating the Decision Tree classifier\")\n",
    "    y_pred_train = dt_classifier.predict(X_train)\n",
    "    log_info(f\"Train Accuracy: {accuracy_score(y_train, y_pred_train)}\")\n",
    "    log_info(f\"{classification_report(y_train, y_pred_train)}\")\n",
    "    log_info(f\"{confusion_matrix(y_train, y_pred_train)}\")\n",
    "\n",
    "    y_pred_test = dt_classifier.predict(X_test)\n",
    "    log_info(f\"Test Accuracy: {accuracy_score(y_test, y_pred_test)}\")\n",
    "    log_info(f\"{classification_report(y_test, y_pred_test)}\")\n",
    "    log_info(f\"{confusion_matrix(y_test, y_pred_test)}\")\n",
    "\n",
    "    log_info(\"Saving the trained Decision Tree model\")\n",
    "    save_model(dt_classifier, 'models/dt_classifier_afib.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve-m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
